<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Bash on Alejandro Inglés Martínez</title><link>https://aleingmar-pi-portfolio.pages.dev/tags/bash/</link><description>Recent content in Bash on Alejandro Inglés Martínez</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 24 Jan 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://aleingmar-pi-portfolio.pages.dev/tags/bash/index.xml" rel="self" type="application/rss+xml"/><item><title>Automatic deployment of multilayer MEAN service on AWS</title><link>https://aleingmar-pi-portfolio.pages.dev/p/stack-mean-terraform/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/stack-mean-terraform/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/stack-mean-terraform/stack.png" alt="Featured image of post Automatic deployment of multilayer MEAN service on AWS" /&gt;&lt;p&gt;This project was developed for the DevOps Tools course, as part of the oficial university&amp;rsquo;s master&amp;rsquo;s degree in Development and Operations (DevOps).&lt;/p&gt;
&lt;p&gt;The aim of the project was to automatically deploy a fully functional multi-tier MEAN system in the AWS cloud. This system consists of a load balancer, several instances for the web application and a dedicated instance for the MongoDB database. I use Terraform, Packer and Ansible for infrastructure automation and provisioning.&lt;/p&gt;
&lt;p&gt;On a personal level, I consider it important to highlight that the documentation report of this project is particularly complete, as it includes all the details of the development process. Among them, I had to deal with three main problems during this process. Without going into too much detail, these were:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deployment on Azure, version incompatibility and choice of AWS.&lt;/li&gt;
&lt;li&gt;Execution of an interactive command blocking the automatic provisioning process.&lt;/li&gt;
&lt;li&gt;Static resource inconsistency and balancer logoff.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In my opinion, these problems are very interesting to analyse, as they are common situations in this type of work. Although they may seem minor, they have been fundamental in the development of the project.&lt;/p&gt;
&lt;p&gt;It is also worth mentioning that for this project I have used similar technologies to those of the project &lt;strong&gt;‘Creation and automated deployment of image in multicloud environment’&lt;/strong&gt;, which is also available in my portfolio. For this reason, in this publication I have decided to highlight three aspects that differentiate both works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The use of the MEAN stack.&lt;/li&gt;
&lt;li&gt;The modularisation of Terraform.&lt;/li&gt;
&lt;li&gt;The deployment process and architecture, although the latter is presented in a summarised form, as it is explained extensively and in detail in the report.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="technology-stack"&gt;Technology Stack
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Terraform&lt;/strong&gt;: with terraform I centralise the whole deployment process, raise and manage the infrastructure elements that make up the system. Some of these elements are for example the networks that connect the different instances, the instances themselves, the load balancer&amp;hellip; In short, the infrastructure that supports the service.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Packer&lt;/strong&gt;: with packer I create the image that serves as a base for the instances that I build with Terraform. In this project, Packer generates a custom image for the first layer of the system, provisioning it with the necessary services such as Node.js, Nginx, Angular&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ansible&lt;/strong&gt;: with Ansible I do the provisioning of the instance that is raised and used by Packer for the creation of the image. In this project, Ansible automatically provisions the instance with Angular, Express, MongoDB, Nginx, Node&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MEAN Stack&lt;/strong&gt;: The system being built is a service made up of the MEAN technology stack, widely used in the industry for its versatility and performance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;MongoDB&lt;/strong&gt;: Non-relational document-oriented database, ideal for handling large volumes of structured and unstructured data.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Express&lt;/strong&gt;: Backend framework for Node.js that facilitates the development of robust and scalable web applications.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Angular&lt;/strong&gt;: Frontend framework that allows the development of modern and reactive interfaces, improving the user experience.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Node.js&lt;/strong&gt;: Execution environment for Js on the server side.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="modularisation-of-the-terraform-template"&gt;Modularisation of the Terraform template
&lt;/h3&gt;&lt;h4 id="importance-of-modularisation"&gt;Importance of modularisation
&lt;/h4&gt;&lt;p&gt;Modularisation in Terraform is vital in projects that use Terraform. It basically consists of dividing the &lt;strong&gt;main.tf&lt;/strong&gt; into different ‘modules’ according to certain categories. Not only does this improve code readability and maintainability, but it also allows responsibilities to be divided and configurations to be reused between projects. Although managing variables between modules can be complex, this practice is essential in large, dynamic infrastructures.&lt;/p&gt;
&lt;h4 id="project-modules"&gt;Project modules
&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Security module&lt;/strong&gt;: This module manages the security groups that define the traffic rules to and from the instances, enabling traffic from protocols such as SSH, HTTP&amp;hellip;. It also configures the SSH keys needed to access the instances remotely.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Network module&lt;/strong&gt;: Defines the networks and private subnets necessary for system connectivity and also configures routing tables and gateways to guarantee access between infrastructure layers.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Instance module&lt;/strong&gt;: Deploys the first and second layer instances, assigning public and private IP addresses and also provisions these instances for proper operation in the system.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load balancer module&lt;/strong&gt;: Configures and defines everything related to the load balancer that distributes the traffic between the instances of the first layer. In addition to the load balancer itself, for this to work it needs more elements such as destination groups, distribution strategies such as round-robin, definition of session persistence&amp;hellip;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Image module&lt;/strong&gt;: This module integrates Terraform with Packer for the creation of base images. Terraform executes &lt;strong&gt;packer build&lt;/strong&gt;, retrieves the generated image and uses it to instantiate resources of the first layer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="../../p/stack-mean-terraform/modulos.png"
width="475"
height="614"
srcset="../../p/stack-mean-terraform/modulos_hu_38e6509afd8e9619.png 480w, ../../p/stack-mean-terraform/modulos_hu_89c902ab49a371c4.png 1024w"
loading="lazy"
alt="Directory structure"
class="gallery-image"
data-flex-grow="77"
data-flex-basis="185px"
&gt;&lt;/p&gt;
&lt;h3 id="deployment-process-and-architecture"&gt;Deployment process and architecture
&lt;/h3&gt;&lt;p&gt;The deployment starts with the integration of Terraform and Packer. Terraform invokes Packer, which is responsible for raising a temporary instance in AWS to generate a base image. During this process, this instance is provisioned with Ansible, which installs and configures services such as Angular, Express and MongoDB, as well as copying essential files from the local environment. Once provisioning is complete, Packer creates the base image and destroys the temporary instance, leaving an image ready for reuse.&lt;/p&gt;
&lt;p&gt;With the image generated, Terraform proceeds to deploy the complete infrastructure. First, the networks and subnets are configured, ensuring internal connectivity between the layers of the system. Next, the first layer instances are deployed using the base image. These instances host the frontend and backend of the application, with Node.js and Nginx serving as the operational core.&lt;/p&gt;
&lt;p&gt;At the same time, Terraform builds the second tier instance, dedicated to data persistence with MongoDB. This instance is connected via a private network to the first layer instances, guaranteeing secure and stable communication. In addition to this, terraform also raises a load balancer, configured to distribute the traffic between the first layer instances, which ensures high availability and scalability.&lt;/p&gt;
&lt;p&gt;The last step is the final provisioning. Terraform uses Bash scripting to finish configuring the deployed instances. For example, in the first layer instances, Angular configurations are adjusted to include the IP addresses of the backend, which allows static files to be generated and served by Nginx with the necessary routes to connect the client to the backend.&lt;/p&gt;
&lt;p&gt;This entire process ensures a fully automated deployment, resulting in a functional, production-ready system, with components integrated and configured for optimal performance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GitHub repository:&lt;/strong&gt;
&lt;a class="link" href="https://github.com/aleingmar/Multi-layer_MEAN_Deployment" target="_blank" rel="noopener"
&gt;https://github.com/aleingmar/Multi-layer_MEAN_Deployment&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="video-of-the-experimentation-and-project-report"&gt;Video of the experimentation and project report:
&lt;/h3&gt;&lt;p&gt;Project documentation: &lt;a class="link" href="../../post/stack-MEAN-Terraform/Act2_StackMEAN_Terraform_AlejandroIngles.pdf" &gt;&lt;strong&gt;View documentation in pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/zRGhkBebEbA"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;</description></item><item><title>Creation and automated deployment of image in multicloud environment.</title><link>https://aleingmar-pi-portfolio.pages.dev/p/imagen-multicloud-packer/</link><pubDate>Sat, 14 Dec 2024 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/imagen-multicloud-packer/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/imagen-multicloud-packer/imagen-multicloud-packer2.png" alt="Featured image of post Creation and automated deployment of image in multicloud environment." /&gt;&lt;p&gt;This project was developed for the DevOps Tools course, as part of the official university master&amp;rsquo;s degree in Development and Operations (DevOps).&lt;/p&gt;
&lt;p&gt;The aim of the project is to &lt;strong&gt;create and automatically deploy an image of a complete web system in a multicloud environment of Azure and AWS&lt;/strong&gt;. This web system is composed of a small application written with Nodejs and a Nginx web server. To achieve this, I use Terraform, Ansible and Packer technologies mainly.&lt;/p&gt;
&lt;h3 id="technologies-used"&gt;Technologies used:
&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Terraform:&lt;/strong&gt; With Terraform I centralize all the execution of the process and deploy the necessary infrastructure to raise an instance in the cloud created from the image of the system and accessible through the internet.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Packer:&lt;/strong&gt; With Packer I build the complete system image. Packer uses the cloud as a provider for the creation of the image. It builds an instance and all the necessary infrastructure for the creation of the image and destroys it when it is finished.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ansible:&lt;/strong&gt; with ansible the provisioning of the instance that packer raises and from which the image is created is carried out. In the case of Azure I do this provisioning with Ansible, in the case of AWS I do the same but directly with Bash scripting.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To control multicloud deployment, a parameter has been implemented that must be passed to the &lt;code&gt;terraform apply ‘deployment_target=’&lt;/code&gt;, indicating whether you want to deploy in both clouds simultaneously or in a single cloud. If this is the case, you must indicate in which one you want to deploy.&lt;/p&gt;
&lt;h3 id="creation-and-deployment-process"&gt;Creation and deployment process:
&lt;/h3&gt;&lt;p&gt;The sequence of steps in the process would be as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Initialise by manually executing a &lt;code&gt;terraform init &amp;amp;&amp;amp; terraform apply&lt;/code&gt; in the shell.&lt;/li&gt;
&lt;li&gt;After that, terraform executes the &lt;code&gt;packer build&lt;/code&gt; command, which takes care of setting up all the necessary infrastructure and the machine used for the creation of the image. In the case of Azure, an Ansible is installed on this machine and it auto-provisions itself by running a playbook and a series of tasks defined in it. In the case of AWS, the same steps are executed, but instead of an Ansible directly by manual scripting in Bash. The provisioning is based among other things on the installation and management of the services: Nodejs, Nginx, pm2 and App.js on the instance that creates the image.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nodejs:&lt;/strong&gt; Provides an environment with everything necessary for the application to run and function correctly.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nginx:&lt;/strong&gt; Web server that will be in charge of redirecting all the traffic to the application and forwarding its responses. It is very important to configure it so that when the image is deployed the server is active and correctly configured to serve the app. Passes traffic from port 80 to port 3000 (where the app.js listens).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PM2:&lt;/strong&gt; Nodejs process manager which is used to ensure that the app.js is active when the image is deployed without having to do anything else (this step is particularly tricky).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;app.js&lt;/strong&gt;: core, functional application of the image, it is important to transfer the source code of the app so that it is accessible by the instance that creates the image.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start="3"&gt;
&lt;li&gt;After this, Packer creates the image and destroys all the infrastructure it has needed to build on the corresponding cloud provider.&lt;/li&gt;
&lt;li&gt;Terraform, after waiting for the image creation to finish successfully, builds all the necessary infrastructure (key pair, security group, disk&amp;hellip;) to build an instance from this image.&lt;/li&gt;
&lt;li&gt;Once the deployment is finished, this instance is accessible through the internet via the public ip.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In short, just by executing a &lt;code&gt;terraform init &amp;amp;&amp;amp; terraform apply&lt;/code&gt; you deploy a functional web environment accessible from the internet in the public cloud of Azure and AWS. And you also create a reusable image so you can deploy more instances identical to these in the future in a much faster and safer way against possible human errors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GitHub repository:&lt;/strong&gt; &lt;a class="link" href="https://github.com/aleingmar/CreateImages_Nginx-Nodejs_Packer" target="_blank" rel="noopener"
&gt;https://github.com/aleingmar/CreateImages_Nginx-Nodejs_Packer&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="repository-contents-and-project-files"&gt;Repository contents and project files:
&lt;/h3&gt;&lt;p&gt;The GiHub repository consists of two main directories with two different versions: &lt;code&gt;/version-2&lt;/code&gt; and &lt;code&gt;/version-3.1&lt;/code&gt;.
The fully functional directory containing the latest version of the project is the second one (&lt;code&gt;/version-3.1&lt;/code&gt;). This is the directory where you have to be located to deploy the &lt;code&gt;terraform init &amp;amp;&amp;amp; terraform apply&lt;/code&gt; (&lt;code&gt;cd version-3.1/te*&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Briefly explaining the contents of the directory:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/packer/&lt;/code&gt;: directory where all the content necessary for Packer to run and build the image is located.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/packer/main.pkr.hcl&lt;/code&gt;: Packer&amp;rsquo;s main file where all the resources needed to build the image are defined as well as all the variables to be used.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/packer/variables.pkrvars.hcl&lt;/code&gt;: file where I assign values to all the variables defined in the &lt;code&gt;main.pkr.hcl&lt;/code&gt; except for the credentials of the two clouds that for security reasons, I define and assign values as environment variables of my host operating system that I use to launch the terraform. I pass these values as parameters in the &lt;code&gt;terraform apply&lt;/code&gt; and &lt;code&gt;packer build&lt;/code&gt; command.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/packer/providers/&lt;/code&gt;: directory where we can find the auxiliary files used to create the image, such as the apache configuration file (&lt;code&gt;nginx_default.conf&lt;/code&gt;), the playbook that defines the provisioning with ansible (&lt;code&gt;provision.yml&lt;/code&gt;) and the nodejs application code (&lt;code&gt;app.js&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/terraform/&lt;/code&gt;: directory where all the content necessary for terraform to run and deploy all the necessary infrastructure for the project is located.
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;/terraform/main.tf&lt;/code&gt;: main file of terraform, where all the process flow that the deployment must follow and all the infrastructure to be deployed is defined.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/terraform/variables.tf&lt;/code&gt;: file where all the variables used by terraform are defined.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;/terraform/terraform.tfvars&lt;/code&gt;: file where all the variables are given values except for the credentials of the two clouds that, for security reasons, I define and assign values in environment variables of my host operating system from where I launch terraform. I pass these values as parameters in the &lt;code&gt;terraform apply&lt;/code&gt; and &lt;code&gt;packer build&lt;/code&gt; command.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="../../p/imagen-multicloud-packer/ficheros.png"
width="400"
height="469"
srcset="../../p/imagen-multicloud-packer/ficheros_hu_7539b2c6371a97d9.png 480w, ../../p/imagen-multicloud-packer/ficheros_hu_ac6cf45573bc6661.png 1024w"
loading="lazy"
alt="Directory content"
class="gallery-image"
data-flex-grow="85"
data-flex-basis="204px"
&gt;&lt;/p&gt;
&lt;h3 id="contents-of-packer-main"&gt;Contents of Packer main:
&lt;/h3&gt;&lt;p&gt;The content of this file can be differentiated in several parts in which the following components necessary for the creation of the image are defined:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PLUGINS&lt;/strong&gt;: Defines the plugins needed for the template.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Definition of variables&lt;/strong&gt;: (no value is assigned here, only maybe the default value).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;BUILDER&lt;/strong&gt;: Define how the AMI is built in AWS &amp;ndash;&amp;gt; &lt;code&gt;source{}&lt;/code&gt;&amp;ndash;&amp;gt; define the base system on which I want to create the image (ubuntu ISO) and the provider for which we create the image (technology with which the image will be deployed) &amp;ndash;&amp;gt; AMAZON. AZURE&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PROVISIONERS&lt;/strong&gt;: Configure the operating system and the application, how the software will be installed and configured &amp;ndash;&amp;gt; &lt;code&gt;build{}&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;GitHub repository:&lt;/strong&gt; &lt;a class="link" href="https://github.com/aleingmar/CreateImages_Nginx-Nodejs_Packer" target="_blank" rel="noopener"
&gt;https://github.com/aleingmar/CreateImages_Nginx-Nodejs_Packer&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="experimentation-video-and-report-of-the-project"&gt;Experimentation video and report of the project:
&lt;/h3&gt;&lt;p&gt;Project documentation: &lt;a class="link" href="../../post/imagen-multicloud-packer/Act1_Packer_AlejandroIngles.pdf" &gt;&lt;strong&gt;View the pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/BhRB0716G5w"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;</description></item><item><title>Automated deployment of Wordpress environment with Ansible</title><link>https://aleingmar-pi-portfolio.pages.dev/p/wp-ansible/</link><pubDate>Fri, 24 Jan 2025 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/wp-ansible/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/wp-ansible/wordpress-ansible.png" alt="Featured image of post Automated deployment of Wordpress environment with Ansible" /&gt;&lt;p&gt;This project was developed for the Deployment Automation Tools course as part of the official university master&amp;rsquo;s degree in Development and Operations (DevOps).&lt;/p&gt;
&lt;p&gt;The main objective of the project was to &lt;strong&gt;automate the local deployment of a complete WordPress environment&lt;/strong&gt; using &lt;strong&gt;Ansible and Vagrant&lt;/strong&gt;. An optimised secure architecture was implemented using &lt;strong&gt;Nginx as a reverse proxy&lt;/strong&gt; that blocks traffic destined for certain sensitive Wordpress administration paths.&lt;/p&gt;
&lt;p&gt;Vagrant creates and raises the virtual machine, on which Ansible is installed. Ansible then automatically self-provisions and configures all the necessary services, including Apache, MySQL, WordPress and Nginx, leaving the system completely ready for use.&lt;/p&gt;
&lt;h2 id="general-structure-of-the-anisble-provisioning-project"&gt;General structure of the Anisble provisioning project
&lt;/h2&gt;&lt;p&gt;The following is the organisation of the Ansible files and roles, to make it easier to understand the general operation of the project:&lt;/p&gt;
&lt;h3 id="main-playbook-provisionplaybookyml"&gt;Main playbook: provision/playbook.yml.
&lt;/h3&gt;&lt;p&gt;This file acts as the starting point for Ansible. From here, the roles needed to configure all the components of the environment are included.
In this case, the code is divided into four roles: apache, mysql, wordpress and nginx, which are executed in this order.
The installation of PHP and its modules has been decided to be included directly in this playbook, instead of creating a separate role, as it is only a few lines of code.
The order of provisioning is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;PHP modules&lt;/li&gt;
&lt;li&gt;Apache&lt;/li&gt;
&lt;li&gt;MySQL&lt;/li&gt;
&lt;li&gt;WordPress&lt;/li&gt;
&lt;li&gt;Nginx&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="variable-management-with-ansible"&gt;Variable management with Ansible
&lt;/h3&gt;&lt;p&gt;Instead of using Hiera as with &lt;strong&gt;Puppet&lt;/strong&gt;, Ansible uses &lt;strong&gt;YAML files&lt;/strong&gt; inside the &lt;code&gt;group_vars/all.yml&lt;/code&gt; directory, allowing variables to be separated from the main code.
This ensures a more secure approach, avoiding exposing sensitive credentials when uploading the project to a repository. Although this project is academic and does not include encrypted variables, Ansible Vault allows you to encrypt variables if necessary.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Variables are declared in: &lt;code&gt;group_vars/all.yml&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Jinja2 (.j2) templates are used to inject dynamic values into the configuration files.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="roles-in-ansible"&gt;Roles in Ansible
&lt;/h3&gt;&lt;p&gt;To better organise the manifests and auxiliary files that Ansible needs for infrastructure configuration automation, I split the content into &lt;strong&gt;four main roles in Ansible&lt;/strong&gt;, each responsible for a part of the system. This allows for &lt;strong&gt;modularity, code reuse and better organisation&lt;/strong&gt; of the playbook.&lt;/p&gt;
&lt;h4 id="apache-role"&gt;Apache Role
&lt;/h4&gt;&lt;p&gt;With this role, Ansible installs and configures the Apache web server, which acts as a backend to serve WordPress. Apache is only accessible from the virtual machine itself, as Nginx will act as a reverse proxy.&lt;/p&gt;
&lt;p&gt;The main tasks it performs are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install Apache and make sure the service is active.&lt;/li&gt;
&lt;li&gt;Remove the default Apache page.&lt;/li&gt;
&lt;li&gt;Configure Apache to listen on &lt;strong&gt;127.0.0.1:8080&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;Setting the listening port to &lt;strong&gt;127.0.0.1:8080&lt;/strong&gt; means that &lt;strong&gt;Apache will only accept connections from local processes on the same machine&lt;/strong&gt; where it is running. &lt;strong&gt;The address 127.0.0.1 is the loopback (localhost) address&lt;/strong&gt;, which prevents access from other machines on the network. This is useful when Apache is behind a reverse proxy, such as Nginx, which handles external connections and forwards requests to Apache on port 8080.’&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Copy the custom configuration from a Jinja2 template (&lt;code&gt;wp-apache-config.conf.j2&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Enable the new site and restart Apache automatically.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this configuration, Apache is kept isolated from shortcuts, ensuring that it can only be queried through Nginx.&lt;/p&gt;
&lt;h4 id="mysql-role"&gt;MySQL Role
&lt;/h4&gt;&lt;p&gt;In this role Ansible provisions the virtual machine with a MySQL database to ensure proper storage and access to WordPress data.&lt;/p&gt;
&lt;p&gt;The main tasks it performs are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install the MySQL server.&lt;/li&gt;
&lt;li&gt;Create the necessary database for WordPress.&lt;/li&gt;
&lt;li&gt;Configure the user and assign the appropriate permissions.&lt;/li&gt;
&lt;li&gt;Execute an initialisation script (&lt;code&gt;init-wordpress.sql.j2&lt;/code&gt;) to prepare the database with the initial structure and data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This role ensures that the database is ready and properly configured before WordPress attempts to connect later by running its role.&lt;/p&gt;
&lt;h4 id="wordpress-role"&gt;WordPress Role
&lt;/h4&gt;&lt;p&gt;This role automates the installation and configuration of WordPress, ensuring a functional and ready-to-use deployment.&lt;/p&gt;
&lt;p&gt;Key tasks it performs include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downloading and extracting WordPress into /var/www/html/wordpress.&lt;/li&gt;
&lt;li&gt;Create and configure the wp-config.php file using a template (&lt;code&gt;wp-config.php.j2&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Ensure correct permissions for WordPress (&lt;code&gt;chown -R www-data:www-data&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Install wp-cli and use it to configure WordPress automatically.&lt;/li&gt;
&lt;li&gt;Initialise the database with minimal content using &lt;code&gt;init-wordpress-content.sql.j2&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Configure Apache to serve WordPress content.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With this role, WordPress is installed, automatically configured and ready for use, without any manual intervention.&lt;/p&gt;
&lt;h4 id="nginx-role"&gt;Nginx Role
&lt;/h4&gt;&lt;p&gt;This role implements &lt;strong&gt;Nginx as a reverse proxy&lt;/strong&gt;, forming the first layer of defence of the system. Its main function is to handle incoming requests and block unwanted access.&lt;/p&gt;
&lt;p&gt;The main actions performed are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Install Nginx in the virtual machine.&lt;/li&gt;
&lt;li&gt;Configure Nginx as a reverse proxy, redirecting requests to Apache on port 8080.&lt;/li&gt;
&lt;li&gt;Block access to sensitive paths such as &lt;code&gt;/wp-admin&lt;/code&gt; and &lt;code&gt;/wp-login.php&lt;/code&gt; to increase security.&lt;/li&gt;
&lt;li&gt;Optimise delivery of static files (CSS, JS, images) directly from Nginx, improving performance.&lt;/li&gt;
&lt;li&gt;Disable the default Nginx page and enable a WordPress-specific configuration.&lt;/li&gt;
&lt;li&gt;Restart Nginx automatically after applying the configuration.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why is Nginx important in this project?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Protects Apache by acting as a single external access point, preventing direct attacks.&lt;/li&gt;
&lt;li&gt;Improves security by blocking access to critical management paths.
With this configuration, Nginx filters traffic and only allows secure requests to WordPress, strengthening the system infrastructure.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="../../p/wp-ansible/roles.png"
width="382"
height="700"
srcset="../../p/wp-ansible/roles_hu_79ce48b7c8b83a2a.png 480w, ../../p/wp-ansible/roles_hu_d1f585e8f9a39b25.png 1024w"
loading="lazy"
alt="Directory structure"
class="gallery-image"
data-flex-grow="54"
data-flex-basis="130px"
&gt;&lt;/p&gt;
&lt;h2 id="system-architecture"&gt;System architecture
&lt;/h2&gt;&lt;h3 id="request-processing-and-data-flow"&gt;&lt;strong&gt;Request processing and data flow&lt;/strong&gt;
&lt;/h3&gt;&lt;p&gt;When a user accesses WordPress, the request follows the following flow:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;The user accesses WordPress from a browser&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nginx receives the request on port 80&lt;/strong&gt; and decides whether to block the request or forward it to Apache.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If the request is valid&lt;/strong&gt;, Nginx forwards it to &lt;strong&gt;Apache on &lt;code&gt;127.0.0.1:8080&lt;/code&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apache processes the request&lt;/strong&gt;, executing the WordPress PHP scripts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If the page requires database data,&lt;/strong&gt; Apache queries MySQL.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apache returns the generated response to Nginx&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Nginx sends the response to the user&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This ensures that &lt;strong&gt;Apache is only accessible from the machine itself&lt;/strong&gt;, while Nginx acts as the first line of defence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Communication between Nginx and Apache&lt;/strong&gt;.
To better understand how the two servers connect, it is important to know how their &lt;strong&gt;ports and IPs&lt;/strong&gt; work:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Nginx listens on &lt;code&gt;0.0.0.0.0:80&lt;/code&gt;&lt;/strong&gt;, which means it accepts connections to port 80 and to any IP that identifies the machine running it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Apache listens on &lt;code&gt;127.0.0.1:8080&lt;/code&gt;&lt;/strong&gt;, which means that this process can only communicate with other processes from the same machine that send traffic to that ip and port 8080.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;127.0.0.1 is the loopback address&lt;/strong&gt;, used for internal communication within the same machine.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;External traffic never reaches Apache directly&lt;/strong&gt;, as Nginx acts as an intermediary.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Key benefit:&lt;/strong&gt; If someone tries to access Apache directly from another machine, the connection will be rejected because &lt;strong&gt;Apache is not exposed to the network&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="conclusion"&gt;Conclusion
&lt;/h2&gt;&lt;p&gt;All in all, simply by going to the console in the directory where the &lt;strong&gt;Vagrantfile&lt;/strong&gt; is located and running a simple &lt;code&gt;vagrant up&lt;/code&gt;, a functional, customised and secure WordPress environment is automatically deployed, accessible from a web client at &lt;code&gt;http://192.168.55.10&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GitHub repository:&lt;/strong&gt;
&lt;a class="link" href="https://github.com/aleingmar/wordpress_ansible" target="_blank" rel="noopener"
&gt;https://github.com/aleingmar/wordpress_ansible&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="experimentation-video-and-project-report"&gt;Experimentation video and project report:
&lt;/h2&gt;&lt;p&gt;Project documentation: &lt;a class="link" href="../../post/wordpress-ansible/Act3_Wordpress_Ansible_AlejandroIngles.pdf" &gt;&lt;strong&gt;View documentation in pdf&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/lksomzUvzA0"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;</description></item><item><title>My own RPI5 server</title><link>https://aleingmar-pi-portfolio.pages.dev/p/my-server/</link><pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/my-server/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/my-server/rasberry.png" alt="Featured image of post My own RPI5 server" /&gt;&lt;p&gt;This project consists of hosting and managing autonomously certain services on my own server, a RasberryPi 5 with 8gb of Ram.&lt;/p&gt;
&lt;p&gt;For the administration and configuration of both the server and its hosted services, I access remotely via SSH protocol.&lt;/p&gt;
&lt;p&gt;The server is associated to a main domain managed by &lt;strong&gt;DuckDNS&lt;/strong&gt;, which allows me to access the services remotely through the browser. To prevent the dynamic IP of my home network from changing and losing access to the server, I have a service that automatically updates this IP every 5 minutes, ensuring that it is always correctly synchronised.&lt;/p&gt;
&lt;p&gt;To organise access via subdomains and ensure connection to my services via &lt;strong&gt;HTTPS&lt;/strong&gt;, I use &lt;strong&gt;Caddy&lt;/strong&gt; as a web server, which acts as an intermediary and handles the TLS/SSL certificates, guaranteeing secure and uncomplicated access.&lt;/p&gt;
&lt;p&gt;In addition, I have implemented an advanced control panel called &lt;strong&gt;Homarr&lt;/strong&gt;, which provides me with a centralised interface from which I can easily log in and access the different services deployed on the server.&lt;/p&gt;
&lt;p&gt;All the services hosted on the server including the ones mentioned above are hosted using &lt;strong&gt;Docker containers&lt;/strong&gt; and are organized in specific subdomains.
At the time of writing, the unmentioned services hosted on the server are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Vaultwarden&lt;/strong&gt;: A password manager.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portainer&lt;/strong&gt;: A container manager with a web interface.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pi-hole&lt;/strong&gt;: An ad-blocking DNS service.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WireGuard&lt;/strong&gt;: A VPN service.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;WireGuard is integrated with Pi-hole. This setup allows me not only to redirect my traffic through my server to secure my connection, but also to enjoy ad-free browsing, no matter where I am.&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/ZHQXSUq01k0"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;</description></item><item><title>Deployment and creation of a web portfolio with Hugo.</title><link>https://aleingmar-pi-portfolio.pages.dev/p/hugo-portfolio/</link><pubDate>Sun, 01 Sep 2024 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/hugo-portfolio/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/hugo-portfolio/hugo-portfolio.png" alt="Featured image of post Deployment and creation of a web portfolio with Hugo." /&gt;&lt;p&gt;This project aims to create a web portfolio to show all the projects I have developed during my academic and personal career, deploy it on my own RPI5 server and make it securely accessible from the internet.&lt;/p&gt;
&lt;h2 id="web-development"&gt;Web Development
&lt;/h2&gt;&lt;p&gt;For the construction of my portfolio I chose &lt;strong&gt;Hugo&lt;/strong&gt;, a static website generation platform that allows you to create modern frontend pages using &lt;strong&gt;Markdown&lt;/strong&gt; files. The decision to use Hugo was based on the fact that I had already written part of my portfolio in Obsidian, a tool (also written in Markdown) that I regularly use to take notes and organise my notes. Hugo&amp;rsquo;s ability to take advantage of Markdown format files allowed me to migrate this content easily and focus more on the quality of the content than on the technical development.&lt;/p&gt;
&lt;p&gt;The theme I selected for my portfolio is &lt;a class="link" href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener"
&gt;hugo-theme-stack&lt;/a&gt;, because of its clean and modern format, which fits perfectly with the structure and design I was looking for. This template, with its focus on performance and simplicity, allowed me to optimise the development of my portfolio without having to invest too much time in interface design. Even so, I have programmed new functionalities that differ from the open source base project for my personal use.&lt;/p&gt;
&lt;h2 id="devops-and-deployment"&gt;DevOps and Deployment
&lt;/h2&gt;&lt;p&gt;In terms of deployment and operational management, my portfolio is hosted on my Raspberry Pi 5 server with 8 GB of RAM, which provides an efficient and energy-efficient solution. To ensure an orderly and isolated environment, I use Docker, where the portfolio runs inside a container. This allows me to package the application independently from the rest of the system, facilitating management and avoiding conflicts with other services running on the same server.&lt;/p&gt;
&lt;p&gt;The web server that handles the requests is &lt;strong&gt;Caddy&lt;/strong&gt;, a lightweight solution that allows me to secure the connection with HTTPS automatically and redirect the traffic to the different services I have deployed. In addition to my own portfolio, I also host the portfolio of a colleague in another container. To monitor the web portfolio I use Google Analytics 4 (GA4) which allows me to see statistics about the accesses to the website.&lt;/p&gt;
&lt;p&gt;For development, I usually work locally using &lt;strong&gt;Visual Studio Code&lt;/strong&gt;, although sometimes I use &lt;strong&gt;GitHub Codespaces&lt;/strong&gt; when I prefer to work in a remote environment. The deployment process is simple: I connect to the server via SSH, pull the latest changes from GitHub and restart the Docker container running Hugo. This workflow is fully automated through a bash script and a Docker Compose file, which simplifies the process of lifting the web application with each update.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Web portfolio change deployment process with bash scripting:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="video-wrapper"&gt;
&lt;iframe loading="lazy"
src="https://www.youtube.com/embed/j6_zmGQ0YFM"
allowfullscreen
title="YouTube Video"
&gt;
&lt;/iframe&gt;
&lt;/div&gt;</description></item><item><title>Web service deployment with EC2 AWS</title><link>https://aleingmar-pi-portfolio.pages.dev/p/aws-ec2-assb/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/aws-ec2-assb/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/aws-ec2-assb/aws-ec2.png" alt="Featured image of post Web service deployment with EC2 AWS" /&gt;&lt;p&gt;This project was developed for a Systems Architectures and Distributed Systems (ASSB) assignment during my fourth year of undergraduate studies. The main objective was to deploy a functional web service in a cloud environment using &lt;strong&gt;AWS&lt;/strong&gt; services, staying within the limits of the free plan.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The deployed web service consists of a load balancer that distributes requests between two EC2 instances, each with its own Apache server and web page.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The main tasks performed included:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Controlling and creating cost alerts&lt;/strong&gt;: Setting up alerts in AWS to ensure that all operations conformed to the free plan, avoiding unwanted additional charges.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deployment of EC2 instances&lt;/strong&gt;: Raise two instances of &lt;strong&gt;EC2&lt;/strong&gt; and connect to them via &lt;strong&gt;SSH&lt;/strong&gt;. On each of the instances, install the &lt;strong&gt;Apache&lt;/strong&gt; web server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Configuring Apache web servers&lt;/strong&gt;: Configuring the Apache services on both instances to serve a static web page created by myself.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Deployment of a load balancer&lt;/strong&gt;: Deployment of a load balancer on AWS to evenly distribute incoming requests between the two Apache servers, optimising the load and ensuring higher availability.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a class="link" href="../../post/aws-ec2-assb/assb-aes-ec2.pdf" &gt;&lt;strong&gt;View memory in pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Parallel computing in distributed systems with MPI.</title><link>https://aleingmar-pi-portfolio.pages.dev/p/mpi-assb/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/mpi-assb/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/mpi-assb/mpi-logo.png" alt="Featured image of post Parallel computing in distributed systems with MPI." /&gt;&lt;p&gt;This project was developed for the course Architecture of Systems and Software Basis (ASSB), during my fourth year of studies. The main objective was to become familiar with parallel programming on distributed memory computers using the &lt;strong&gt;MPI&lt;/strong&gt; library in &lt;strong&gt;C&lt;/strong&gt; (Message-Passing Interface). A widely used technique for distributed computing on multiple machines, commonly used in high performance clusters. In the case of this project everything was executed in my own computer, understanding my computer as a kind of cluster and its different cores as machines that form it.&lt;/p&gt;
&lt;p&gt;The main tasks of this project are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Development of the ‘Hello World’ program with MPI&lt;/strong&gt;: As a first step, I programmed a basic program so that &lt;strong&gt;each process would print a message with its rank and the name of the processor it was running on&lt;/strong&gt;. In addition, I experimented with the possibility of launching more processes than the number of physical cores available, observing how MPI handles this scenario even though it loses performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Scalar product of vectors in parallel&lt;/strong&gt;: I implemented a program with MPI that &lt;strong&gt;computes the scalar product of two large vectors&lt;/strong&gt;, distributing the work among several processes. Each process calculated a part of the scalar product, and then the results were brought together in the process of rank 0, which displayed the total result. A runtime measurement was also added, allowing analysis of how performance varied as the number of processes changed.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Solving integrals using the trapezoid method&lt;/strong&gt;: I then &lt;strong&gt;implemented a program to calculate integrals using the trapezoid method&lt;/strong&gt;, parallelising the program so that each process calculated the sum of the trapezoids in a specific sub-interval. As before, the process at rank 0 was responsible for summing the results of all the processes and displaying the final value of the integral.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Performance and scalability analysis&lt;/strong&gt;: To evaluate the performance of the parallel program, I measured execution times and speedup when using different numbers of processes, from 1 to more than twice the number of available physical cores. The results were visualised in graphs showing how speedup improved as the number of processes increased, but also how efficiency decreased at certain points due to overhead in inter-process communication.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Project documentation: &lt;a class="link" href="../../post/paralelizacion-mpi-assb/ASSB-mpi.pdf" &gt;&lt;strong&gt;View documentation in pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Parallel computing on multicore processors with OpenMP.</title><link>https://aleingmar-pi-portfolio.pages.dev/p/openmp-assb/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://aleingmar-pi-portfolio.pages.dev/p/openmp-assb/</guid><description>&lt;img src="https://aleingmar-pi-portfolio.pages.dev/p/openmp-assb/openmp-logo.png" alt="Featured image of post Parallel computing on multicore processors with OpenMP." /&gt;&lt;p&gt;This project was developed during the Systems and Software Architecture and Basis (ASSB) course during my fourth year of studies. The main objective was to implement an algorithm for calculating the Pi number using the MonteCarlo method by programming in C both sequentially and using parallel programming techniques to take full advantage of the resources of multicore processors using the OpenMP library, which allows code to be executed in multiple threads efficiently.&lt;/p&gt;
&lt;p&gt;The main tasks performed were the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Development of the sequential and parallel version of the algorithm&lt;/strong&gt;: I implemented a program that simulates the throwing of random ‘darts’ inside a square inscribed in a circle. The ratio between the hits inside the circle and the total throws is used to calculate the value of Pi. In the parallel version, I used OpenMP to divide the work among several threads, taking full advantage of the resources of multi-core processors.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Time measurements and performance analysis&lt;/strong&gt;: After developing the two versions of the program, I performed time measurements to evaluate the performance of the parallel version compared to the sequential version. I used different thread configurations, from a single thread to more than twice the physical cores of the processor, in order to analyse the speedup and scalability of the algorithm. The speedup was calculated as the ratio between the single-threaded execution time and the multi-threaded execution time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Optimisation and management of shared resources&lt;/strong&gt;: During development, it was necessary to solve common problems in parallel programming, such as race conditions. In this case, I used OpenMP directives to define private variables on a per-thread basis, preventing multiple threads from simultaneously accessing the same global variables and affecting the final result.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Generating performance graphs&lt;/strong&gt;: After collecting runtime and speedup data, I generated graphs to visualise the performance of the program as the number of threads increased. These graphs demonstrated how the application scaled with increased thread count, highlighting the advantages and limitations of parallelisation in a shared-memory environment.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Project documentation: &lt;a class="link" href="../../post/paralelizacion-openmp-assb/ASSB-openmp.pdf" &gt;&lt;strong&gt;View documentation in pdf&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description></item></channel></rss>